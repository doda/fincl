# AUTOGENERATED! DO NOT EDIT! File to edit: dev/21_tearsheets.ipynb (unless otherwise specified).

__all__ = ['mean_of_dfs', 'make_default_config', 'abort_early', 'load_payloads', 'join_signals',
           'create_frontend_payload', 'get_volatilities', 'calc_returns', 'create_tearsheet', 'get_config', 'FORMAT']

# Cell

import pyfolio
from pyfolio.timeseries import perf_stats, gen_drawdown_table
import numpy as np
import pandas as pd
from path import Path
from pprint import pprint
from functools import reduce
import datetime
import logging
import re

import simplejson as json

from .historical_bt import simulate_pnl
from .pnl_sim import get_pnl_reports
from .feature_eng import engineer_feature

try:
    from mlbt import settings_pers as settings
except:
    from mlbt import settings

FORMAT = "%(asctime)-15s %(message)s"
logging.basicConfig(format=FORMAT, level=logging.INFO)

def mean_of_dfs(dfs):
    return reduce(lambda left, right: left.add(right), dfs) / len(dfs)


def make_default_config(**data):
    DATA_DIR = data.get("DATA_DIR", settings.DATA_DIR)

    return {
        "DATA_DIR": DATA_DIR,
        "F_PAYLOAD_DIR": data.get("F_PAYLOAD_DIR", settings.F_PAYLOAD_DIR),
        "symbols_map": pd.read_csv(DATA_DIR / "symbols.csv", index_col="iqsymbol"),
    }


def abort_early(force, file_name):
    have_file = False
    if not force:
        try:
            # Check if we already have the file we want to create
            with open(file_name) as f:
                have_file = bool(json.load(f))
        except:
            pass
        if have_file:
            return True
    return False


def load_payloads(file_names, our_config):
    res = []
    for file_name in file_names:
        with open(file_name) as f:
            pay_j = json.load(f)

        events = pd.DataFrame.from_dict(pay_j["events"])
        events = events.set_index(pd.to_datetime(events.index))
        events["t1"] = pd.to_datetime(events["t1"])
        config = get_config(pay_j, file_name)
        config = {**config, **our_config}

        closes, clf_signals, alpha_signals = get_pnl_reports(
            events,
            pay_j["symbols"],
            config["binarize"],
            config["binarize_params"],
        )
        logging.info(f"clf_signals shape {clf_signals.shape}")

        primary_signals, secondary_signals = (
            (alpha_signals, clf_signals)
            if alpha_signals is not None
            else (clf_signals, alpha_signals)
        )
        res.append((config, pay_j, events, closes, primary_signals, secondary_signals))

    return res

def join_signals(dfs):
    cols = dfs[0].columns
    signals = []
    for col in cols:
        symbol_signals = pd.concat([df[col] for df in dfs if col in df], axis=1).ffill().mean(axis=1)
        signals.append(symbol_signals)
    res = pd.concat(signals, axis=1).ffill()
    res.columns = cols
    return res


def create_frontend_payload(file_names, force=False, our_config=None):
    if our_config is None:
        our_config = make_default_config()

    combine_multi = len(file_names) > 1
    if combine_multi:
        new_file_name = our_config["F_PAYLOAD_DIR"] / f"f_payload_MULTI_{len(file_names)}.json"
    else:
        new_file_name = our_config["F_PAYLOAD_DIR"] / file_names[0].basename().replace("payload_", "f_payload_", 1)

    if abort_early(force, new_file_name):
        return

    payloads = load_payloads(file_names, our_config)
    configs, pay_js, events, closes, primary_signals, secondary_signals = zip(*payloads)
    config = configs[0]
    config['start_date'] = pd.Timestamp(config['start_date'])
    config['end_date'] = pd.Timestamp(config['end_date'])

    pay_j = pay_js[0]
    events = events[0]
    closes = closes[0]
    primary_signals = join_signals(primary_signals)

    if secondary_signals[0]:
        secondary_signals = join_signals(secondary_signals)

    primary_rets, pay_j["primary"]["pnl"] = create_tearsheet(
        config, events, closes, primary_signals, new_file_name, "primary"
    )
    if pay_j["secondary"]:
        _, pay_j["secondary"]["pnl"] = create_tearsheet(
            config, events, closes, secondary_signals, new_file_name, "secondary", primary_rets
        )

    # Delete stuff we don't want in the frontend payload
    del pay_j["events"]
    del pay_j["symbols"]

    logging.info(f"Writing f_payload at {new_file_name}")
    with open(new_file_name, "w") as f:
        json.dump(pay_j, f, ignore_nan=True, default=datetime.datetime.isoformat)
    return new_file_name

def get_volatilities(config, close, span=32):
    daily_bars = {
        'name': 'make_bars', 'type_': 'time', 'size': 1, 'resolution': 'D'
    }
    feat = {'name': 'ewm_stdev', 'window': span, 'symbol': {
        'name': 'log_ret', 'symbol': daily_bars
    }}
    vols = pd.concat([engineer_feature({}, symbol, config, feat)['Close'] for symbol in close.columns], axis=1)
    vols.columns = close.columns
    return vols.reindex(close.index, method='pad')

def calc_returns(df):
    df = df.resample("1B").last()

    if str(df.index.tz) != "UTC":
        df.index = df.index.tz_localize(tz="UTC")

    return df.pct_change()

def create_tearsheet(config, events, close, signal, file_name, report_type, benchmark_rets=None):
    logging.info(f"Creating {report_type} tearsheet for {file_name}")
    # Due to our train/test split we have few symbols at the beginning of our data sets

    # Map long/short to long/flat
#     signal = (signal + 1) / 2
    pos_size = 50000
    volatilities = get_volatilities(config, close)
    df_net, _, cost_stats, _, _ = simulate_pnl(config, close, signal, volatilities, pos_size)
    returns_net = calc_returns(df_net)
    returns_net.name = report_type.title()

    if report_type == "primary":
        long_all = pd.DataFrame(1, columns=signal.columns, index=signal.index)
        df_bench, *_ = simulate_pnl(config, close, long_all, volatilities, pos_size)
        benchmark_rets = calc_returns(df_bench)
        benchmark_rets.name = "Benchmark (long all)"

    fig = pyfolio.create_returns_tear_sheet(
        returns_net,
        benchmark_rets=benchmark_rets,
        return_fig=True
    )
    fig_file_name = file_name.replace(".json", f"_{report_type}.png")
    fig.savefig(fig_file_name, bbox_inches="tight", pad_inches=0)

    p_stats = perf_stats(returns_net)
    dd_table = gen_drawdown_table(returns_net, 5)

    signal = signal.resample("1B").last()
    # Just-in-case normalize to 1 for reporting
    signal = signal / signal.max().max()
    signal.plot()
    signal = signal.set_index(signal.index.map(lambda x: x.isoformat()))


    return (
        returns_net,
        {
            "fig_file_name": str(Path(fig_file_name).basename()),
            "p_stats": p_stats.to_dict(),
            "dd_table": dd_table.to_dict(),
            "signal": signal.to_csv(),  # CSV is a lot more space-efficient for this dense 1500*50 table
            "cost_stats": cost_stats,
        },
    )


def get_config(payload, fn):
    if "config" in payload:
        return payload["config"]

    # bridge to the old payload format
    if "fixed_horizon" in fn:
        return {
            "binarize": "fixed_horizon",
            "binarize_params": int(re.findall(r"fixed_horizon_(\d+)", fn)[0]),
        }
    return {}