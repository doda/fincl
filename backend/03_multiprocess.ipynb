{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp multiprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "# Linear Partitions [20.4.1]\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import sys\n",
    "import os\n",
    "\n",
    "\n",
    "def lin_parts(num_atoms, num_threads):\n",
    "    # partition of atoms with a single loop\n",
    "    parts = np.linspace(0, num_atoms, min(num_threads, num_atoms) + 1)\n",
    "    parts = np.ceil(parts).astype(int)\n",
    "    return parts\n",
    "\n",
    "\n",
    "def nested_parts(num_atoms, num_threads, upper_triang=False):\n",
    "    # partition of atoms with an inner loop\n",
    "    parts, num_threads_ = [0], min(num_threads, num_atoms)\n",
    "    for num in range(num_threads_):\n",
    "        part = 1 + 4 * (\n",
    "            parts[-1] ** 2 + parts[-1] + num_atoms * (num_atoms + 1.0) / num_threads_\n",
    "        )\n",
    "        part = (-1 + part ** 0.5) / 2.0\n",
    "        parts.append(part)\n",
    "    parts = np.round(parts).astype(int)\n",
    "    if upper_triang:  # the first rows are heaviest\n",
    "        parts = np.cumsum(np.diff(parts)[::-1])\n",
    "        parts = np.append(np.array([0]), parts)\n",
    "    return parts\n",
    "\n",
    "\n",
    "def mp_pandas_obj(func, pd_obj, num_threads=32, mp_batches=1, lin_mols=True, combine_results=True, **kargs):\n",
    "    \"\"\"\n",
    "    Parallelize jobs, return a dataframe or series\n",
    "    + func: function to be parallelized. Returns a DataFrame\n",
    "    + pd_obj[0]: Name of argument used to pass the molecule\n",
    "    + pd_obj[1]: List of atoms that will be grouped into molecules\n",
    "    + kwds: any other argument needed by func\n",
    "    Example: df1=mp_pandas_obj(func,('molecule',df0.index),24,**kwds)\n",
    "    \"\"\"\n",
    "    import pandas as pd\n",
    "\n",
    "    if lin_mols:\n",
    "        parts = lin_parts(len(pd_obj[1]), num_threads * mp_batches)\n",
    "    else:\n",
    "        parts = nested_parts(len(pd_obj[1]), num_threads * mp_batches)\n",
    "\n",
    "    jobs = []\n",
    "    for i in range(1, len(parts)):\n",
    "        job = {pd_obj[0]: pd_obj[1][parts[i - 1] : parts[i]], \"func\": func}\n",
    "        job.update(kargs)\n",
    "        jobs.append(job)\n",
    "    if num_threads == 1:\n",
    "        out = process_jobs_(jobs)\n",
    "    else:\n",
    "        out = process_jobs(jobs, num_threads=num_threads)\n",
    "    if not combine_results:\n",
    "        return out\n",
    "    if isinstance(out[0], pd.DataFrame):\n",
    "        df0 = pd.DataFrame()\n",
    "    elif isinstance(out[0], pd.Series):\n",
    "        df0 = pd.Series()\n",
    "    else:\n",
    "        return out\n",
    "    for i in out:\n",
    "        df0 = df0.append(i)\n",
    "    df0 = df0.sort_index()\n",
    "    return df0\n",
    "\n",
    "\n",
    "# =======================================================\n",
    "# single-thread execution for debugging [20.8]\n",
    "def process_jobs_(jobs):\n",
    "    # Run jobs sequentially, for debugging\n",
    "    out = []\n",
    "    for job in jobs:\n",
    "        out_ = expand_call(job)\n",
    "        out.append(out_)\n",
    "    return out\n",
    "\n",
    "\n",
    "# =======================================================\n",
    "# Example of async call to multiprocessing lib [20.9]\n",
    "import multiprocessing as mp\n",
    "import datetime as dt\n",
    "\n",
    "# ________________________________\n",
    "def report_progress(job_num, num_jobs, time0, task):\n",
    "    # Report progress as asynch jobs are completed\n",
    "    msg = [float(job_num) / num_jobs, (time.time() - time0) / 60.0]\n",
    "    msg.append(msg[1] * (1 / msg[0] - 1))\n",
    "    time_stamp = str(dt.datetime.fromtimestamp(time.time()))\n",
    "    msg = (\n",
    "        time_stamp\n",
    "        + \" \"\n",
    "        + str(round(msg[0] * 100, 2))\n",
    "        + \"% \"\n",
    "        + task\n",
    "        + \" done after \"\n",
    "        + str(round(msg[1], 2))\n",
    "        + \" minutes. Remaining \"\n",
    "        + str(round(msg[2], 2))\n",
    "        + \" minutes.\"\n",
    "    )\n",
    "    if job_num < num_jobs:\n",
    "        sys.stderr.write(msg + \"\\r\")\n",
    "    else:\n",
    "        sys.stderr.write(msg + \"\\n\")\n",
    "    return\n",
    "\n",
    "\n",
    "# ________________________________\n",
    "def process_jobs(jobs, task=None, num_threads=36):\n",
    "    # Run in parallel.\n",
    "    # jobs must contain a 'func' callback, for expandCall\n",
    "    if task is None:\n",
    "        task = jobs[0][\"func\"].__name__\n",
    "    pool = mp.Pool(processes=num_threads)\n",
    "    outputs, out, time0 = pool.imap_unordered(expand_call, jobs), [], time.time()\n",
    "    # Process asyn output, report progress\n",
    "    for i, out_ in enumerate(outputs, 1):\n",
    "        out.append(out_)\n",
    "        report_progress(i, len(jobs), time0, task)\n",
    "    pool.close()\n",
    "    pool.join()  # this is needed to prevent memory leaks\n",
    "    return out\n",
    "\n",
    "\n",
    "# =======================================================\n",
    "# Unwrapping the Callback [20.10]\n",
    "def expand_call(kargs):\n",
    "    # Expand the arguments of a callback function, kargs['func']\n",
    "    func = kargs[\"func\"]\n",
    "    del kargs[\"func\"]\n",
    "    out = func(**kargs)\n",
    "    return out\n",
    "\n",
    "\n",
    "# =======================================================\n",
    "# Pickle Unpickling Objects [20.11]\n",
    "def _pickle_method(method):\n",
    "    func_name = method.im_func.__name__\n",
    "    obj = method.im_self\n",
    "    cls = method.im_class\n",
    "    return _unpickle_method, (func_name, obj, cls)\n",
    "\n",
    "\n",
    "# ________________________________\n",
    "def _unpickle_method(func_name, obj, cls):\n",
    "    for cls in cls.mro():\n",
    "        try:\n",
    "            func = cls.__dict__[func_name]\n",
    "        except KeyError:\n",
    "            pass\n",
    "        else:\n",
    "            break\n",
    "    return func.__get__(obj, cls)\n",
    "\n",
    "\n",
    "# ________________________________"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
