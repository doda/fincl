{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import logging\n",
    "import tpot\n",
    "\n",
    "from mlbt.utils import PurgedKFold\n",
    "from math import ceil\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.dummy import DummyClassifier\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "# from dask.distributed import Client\n",
    "# client = Client()\n",
    "\n",
    "\n",
    "def tpot_fit(events, X_all, y_all, num_threads):\n",
    "    inner_cv = PurgedKFold(\n",
    "        n_splits=5, t1=events[\"t1\"], pct_embargo=0, random_state=42,\n",
    "    )\n",
    "    clf = tpot.TPOTClassifier(generations=500,\n",
    "                              population_size=60,\n",
    "                              offspring_size=None,\n",
    "#                               mutation_rate=0.9,\n",
    "#                               crossover_rate=0.1,\n",
    "                              scoring='neg_log_loss',\n",
    "                              cv=inner_cv,\n",
    "#                               subsample=1.0,\n",
    "                              n_jobs=num_threads,\n",
    "                              max_time_mins=500,\n",
    "                              max_eval_time_mins=5,\n",
    "                              random_state=42, \n",
    "                              periodic_checkpoint_folder='checks',\n",
    "#                               use_dask=True,\n",
    "                              config_dict='TPOT light',\n",
    "                              verbosity=2,)\n",
    "\n",
    "    clf.fit(X_all, y_all)\n",
    "    clf.export('tpot_pipeline.py')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def clf_hyper_fit(\n",
    "    feat,\n",
    "    lbl,\n",
    "    t1,\n",
    "    pipe_clf,\n",
    "    param_grid,\n",
    "    cv=3,\n",
    "    bagging=[0, None, 1.0],\n",
    "    rnd_search_iter=0,\n",
    "    n_jobs=-1,\n",
    "    pct_embargo=0,\n",
    "    **fit_params,\n",
    "):\n",
    "    if set(lbl.values) == {0, 1}:\n",
    "        scoring = \"f1\"  # f1 for meta-labeling\n",
    "    else:\n",
    "        scoring = \"neg_log_loss\"  # symmetric towards all classes\n",
    "\n",
    "    # 1) hyperparameter searching, on train data\n",
    "    inner_cv = PurgedKFold(\n",
    "        n_splits=cv, t1=t1, pct_embargo=pct_embargo, random_state=None\n",
    "    )\n",
    "    if rnd_search_iter == 0:\n",
    "        gs = GridSearchCV(\n",
    "            estimator=pipe_clf,\n",
    "            param_grid=param_grid,\n",
    "            scoring=scoring,\n",
    "            cv=inner_cv,\n",
    "            n_jobs=n_jobs,\n",
    "            iid=False,\n",
    "        )\n",
    "    else:\n",
    "        gs = RandomizedSearchCV(\n",
    "            estimator=pipe_clf,\n",
    "            param_distributions=param_grid,\n",
    "            scoring=scoring,\n",
    "            cv=inner_cv,\n",
    "            n_jobs=n_jobs,\n",
    "            iid=False,\n",
    "            n_iter=rnd_search_iter,\n",
    "        )\n",
    "    gs = gs.fit(feat, lbl, **fit_params)\n",
    "    return gs\n",
    "\n",
    "\n",
    "RF_PARAM_GRID = {\n",
    "    \"n_estimators\": np.arange(25, 525, 25),\n",
    "    \"max_depth\": np.arange(1, 11, 1),\n",
    "}\n",
    "\n",
    "XGB_PARAM_GRID = {\n",
    "    \"max_depth\": np.arange(1, 8, 1),\n",
    "    \"colsample_bytree\": np.arange(0.3, 1.1, 0.1),\n",
    "    \"gamma\": np.arange(0.0, 0.55, 0.05),\n",
    "    \"n_estimators\": np.arange(25, 275, 25),\n",
    "}\n",
    "\n",
    "LGBM_PARAM_GRID = {\n",
    "    \"max_depth\": np.arange(1, 8, 1),\n",
    "    \"num_leaves\": np.arange(8, 130, 2),\n",
    "    \"colsample_bytree\": np.arange(0.3, 1.05, 0.05),\n",
    "    \"n_estimators\": np.arange(25, 275, 25),\n",
    "}\n",
    "\n",
    "KNN_PARAM_GRID = {\"n_neighbors\": np.arange(1, 31, 1), \"p\": np.arange(1, 4, 1)}\n",
    "\n",
    "SVC_PARAM_GRID = {\n",
    "    \"C\": [0.1, 1, 10, 100, 1000],\n",
    "    \"gamma\": [1, 0.1, 0.01, 0.001, 0.0001],\n",
    "    \"probability\": [True],\n",
    "}\n",
    "\n",
    "PARALLELIZABLE = [\"xgboost\", \"lgbm\", \"knn\"]\n",
    "\n",
    "\n",
    "def get_model(\n",
    "    events,\n",
    "    X_all,\n",
    "    y_all,\n",
    "    clf_type,\n",
    "    optimize_hypers,\n",
    "    hypers_n_iter,\n",
    "    num_threads=32,\n",
    "    n_jobs=4,\n",
    "    hyper_params=None,\n",
    "):\n",
    "    # X_all and y_all in this context are X_train and y_train in the grander scheme\n",
    "    logging.info(f\"Getting model {clf_type}\")\n",
    "    if clf_type == \"tpot\":\n",
    "        return tpot_fit(events, X_all, y_all, num_threads)\n",
    "    \n",
    "    param_grids = {\n",
    "        \"random_forest\": RF_PARAM_GRID,\n",
    "        \"xgboost\": XGB_PARAM_GRID,\n",
    "        \"lgbm\": LGBM_PARAM_GRID,\n",
    "        \"svc\": SVC_PARAM_GRID,\n",
    "        \"knn\": KNN_PARAM_GRID,\n",
    "        \"dummy\": {},\n",
    "    }\n",
    "    clfs = {\n",
    "        \"random_forest\": RandomForestClassifier,\n",
    "        \"xgboost\": XGBClassifier,\n",
    "        \"lgbm\": LGBMClassifier,\n",
    "        \"svc\": SVC,\n",
    "        \"knn\": KNeighborsClassifier,\n",
    "        \"dummy\": DummyClassifier,\n",
    "    }\n",
    "\n",
    "    hyper_params = hyper_params or {}\n",
    "    extra_hyper_params = {}\n",
    "\n",
    "    # Balance class weights\n",
    "    if clf_type == \"random_forest\":\n",
    "        extra_hyper_params[\"class_weight\"] = \"balanced_subsample\"\n",
    "    if clf_type in [\"xgboost\", \"lgbm\"]:\n",
    "        neg, pos = y_all.value_counts().values\n",
    "        extra_hyper_params[\"scale_pos_weight\"] = neg / pos\n",
    "\n",
    "    clf = clfs[clf_type](**hyper_params, **extra_hyper_params)\n",
    "\n",
    "    param_grid = param_grids[clf_type]\n",
    "    if not param_grid:  # nothing to do\n",
    "        return clf, hyper_params\n",
    "\n",
    "    if not hyper_params and optimize_hypers:\n",
    "        # We generally expect to be run with high num_threads which means we don't have to parallelize at the clf level here\n",
    "        clf.n_jobs = 1\n",
    "        logging.info(\n",
    "            f\"hyperparam search n_iter={hypers_n_iter} for {clf_type} on num_threads={num_threads} and n_jobs={clf.n_jobs}\"\n",
    "        )\n",
    "        \n",
    "        search = clf_hyper_fit(\n",
    "            feat=X_all,\n",
    "            lbl=y_all,\n",
    "            t1=events[\"t1\"],\n",
    "            pipe_clf=clf,\n",
    "            param_grid=param_grid,\n",
    "            rnd_search_iter=hypers_n_iter,\n",
    "            n_jobs=num_threads,\n",
    "        )\n",
    "        search_results = pd.DataFrame(search.cv_results_)\n",
    "        best1_idx = search_results[\"mean_test_score\"].idxmax()\n",
    "\n",
    "        clf, hyper_params = (\n",
    "            search.best_estimator_,\n",
    "            search_results.iloc[best1_idx][\"params\"],\n",
    "        )\n",
    "\n",
    "    clf.n_jobs = n_jobs\n",
    "    return clf, hyper_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
