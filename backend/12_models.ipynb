{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import logging\n",
    "# import tpot\n",
    "\n",
    "from mlbt.utils import PurgedKFold\n",
    "from math import ceil\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.dummy import DummyClassifier\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "\n",
    "def undersample(events, X, y):\n",
    "    from imblearn.under_sampling import RandomUnderSampler\n",
    "    under = RandomUnderSampler()\n",
    "\n",
    "    _, _ = under.fit_sample(X, y)\n",
    "    X_re = X.iloc[under.sample_indices_].sort_index()\n",
    "    y_re = y.iloc[under.sample_indices_].sort_index()\n",
    "    events_re = events.iloc[under.sample_indices_].sort_index()\n",
    "    return events_re, X_re, y_re\n",
    "    \n",
    "\n",
    "def clf_hyper_fit(\n",
    "    feat,\n",
    "    lbl,\n",
    "    t1,\n",
    "    pipe_clf,\n",
    "    param_grid,\n",
    "    cv=5,\n",
    "    bagging=[0, None, 1.0],\n",
    "    rnd_search_iter=0,\n",
    "    n_jobs=-1,\n",
    "    pct_embargo=0,\n",
    "    **fit_params,\n",
    "):\n",
    "    if set(lbl.values) == {0, 1}:\n",
    "        scoring = \"f1\"  # f1 for meta-labeling\n",
    "    else:\n",
    "        scoring = \"neg_log_loss\"  # symmetric towards all classes\n",
    "\n",
    "    # 1) hyperparameter searching, on train data\n",
    "    inner_cv = PurgedKFold(\n",
    "        n_splits=cv, t1=t1, pct_embargo=pct_embargo, random_state=None\n",
    "    )\n",
    "    if rnd_search_iter == 0:\n",
    "        gs = GridSearchCV(\n",
    "            estimator=pipe_clf,\n",
    "            param_grid=param_grid,\n",
    "            scoring=scoring,\n",
    "            cv=inner_cv,\n",
    "            n_jobs=n_jobs,\n",
    "            iid=False,\n",
    "        )\n",
    "    else:\n",
    "        gs = RandomizedSearchCV(\n",
    "            estimator=pipe_clf,\n",
    "            param_distributions=param_grid,\n",
    "            scoring=scoring,\n",
    "            cv=inner_cv,\n",
    "            n_jobs=n_jobs,\n",
    "            iid=False,\n",
    "            n_iter=rnd_search_iter,\n",
    "        )\n",
    "    gs = gs.fit(feat, lbl, **fit_params)\n",
    "    return gs\n",
    "\n",
    "\n",
    "RF_PARAM_GRID = {\n",
    "    \"n_estimators\": np.arange(10, 200, 10),\n",
    "    \"max_depth\": np.arange(1, 11, 1),\n",
    "}\n",
    "\n",
    "XGB_PARAM_GRID = {\n",
    "    \"eta\": np.arange(0.2, 0.41, 0.01),\n",
    "    \"max_depth\": np.arange(1, 8, 1),\n",
    "    \"colsample_bytree\": np.arange(0.3, 1.1, 0.1),\n",
    "    \"gamma\": np.arange(0.0, 0.55, 0.05),\n",
    "    \"n_estimators\": np.arange(25, 275, 25),\n",
    "    \"min_child_weight\": np.arange(1, 10, 1),\n",
    "}\n",
    "\n",
    "LGBM_PARAM_GRID = {\n",
    "    \"max_depth\": np.arange(1, 8, 1),\n",
    "    \"num_leaves\": np.arange(8, 130, 2),\n",
    "    \"colsample_bytree\": np.arange(0.3, 1.05, 0.05),\n",
    "    \"n_estimators\": np.arange(25, 275, 25),\n",
    "    \"learning_rate\": np.arange(0.01, 0.2, 0.01),\n",
    "}\n",
    "\n",
    "KNN_PARAM_GRID = {\"n_neighbors\": np.arange(1, 31, 1), \"p\": np.arange(1, 4, 1)}\n",
    "\n",
    "SVC_PARAM_GRID = {\n",
    "    \"C\": [0.1, 1, 10, 100, 1000],\n",
    "    \"gamma\": [1, 0.1, 0.01, 0.001, 0.0001],\n",
    "    \"probability\": [True],\n",
    "    \"max_iter\": [100000],\n",
    "}\n",
    "\n",
    "\n",
    "def get_model(\n",
    "    events,\n",
    "    X_all,\n",
    "    y_all,\n",
    "    clf_type,\n",
    "    optimize_hypers,\n",
    "    hypers_n_iter,\n",
    "    num_threads=32,\n",
    "    n_jobs=4,\n",
    "    hyper_params=None,\n",
    "):\n",
    "    # X_all and y_all in this context are X_train and y_train in the grander scheme\n",
    "    logging.info(f\"Getting model {clf_type}\")\n",
    "    param_grids = {\n",
    "        \"random_forest\": RF_PARAM_GRID,\n",
    "        \"xgboost\": XGB_PARAM_GRID,\n",
    "        \"lgbm\": LGBM_PARAM_GRID,\n",
    "        \"svc\": SVC_PARAM_GRID,\n",
    "        \"knn\": KNN_PARAM_GRID,\n",
    "        \"dummy\": {},\n",
    "    }\n",
    "    clfs = {\n",
    "        \"random_forest\": RandomForestClassifier,\n",
    "        \"xgboost\": XGBClassifier,\n",
    "        \"lgbm\": LGBMClassifier,\n",
    "        \"svc\": SVC,\n",
    "        \"knn\": KNeighborsClassifier,\n",
    "        \"dummy\": DummyClassifier,\n",
    "    }\n",
    "\n",
    "    hyper_params = hyper_params or {}\n",
    "    extra_hyper_params = {}\n",
    "\n",
    "    clf = clfs[clf_type](**hyper_params, **extra_hyper_params)\n",
    "\n",
    "    param_grid = param_grids[clf_type]\n",
    "    if not param_grid:  # nothing to do\n",
    "        return clf, hyper_params\n",
    "\n",
    "    if not hyper_params and optimize_hypers:\n",
    "        # We generally expect to be run with high num_threads which means we don't have to parallelize at the clf level here\n",
    "#         clf.n_jobs = 1\n",
    "        logging.info(\n",
    "            f\"hyperparam search n_iter={hypers_n_iter} for {clf_type} on num_threads={num_threads} and n_jobs={clf.n_jobs}\"\n",
    "        )\n",
    "        events_re, X_re, y_re = undersample(events, X_all, y_all)\n",
    "        search = clf_hyper_fit(\n",
    "            feat=X_re,\n",
    "            lbl=y_re,\n",
    "            t1=events_re[\"t1\"],\n",
    "            pipe_clf=clf,\n",
    "            param_grid=param_grid,\n",
    "            rnd_search_iter=hypers_n_iter,\n",
    "            n_jobs=num_threads,\n",
    "        )\n",
    "\n",
    "        clf, hyper_params = search.best_estimator_, search.best_params_\n",
    "\n",
    "    if clf_type == 'random_forest':\n",
    "        clf.n_jobs = min(8, n_jobs) # Doesn't like high n_jobs\n",
    "    else:\n",
    "        clf.n_jobs = n_jobs\n",
    "\n",
    "    return clf, hyper_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from path import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "events = pd.read_hdf(Path('~/Dropbox/algotrading/data_trash/events_train.h5').expanduser(), 'table')\n",
    "X = pd.read_hdf(Path('~/Dropbox/algotrading/data_trash/X_train.h5').expanduser(), 'table')\n",
    "y = pd.read_hdf(Path('~/Dropbox/algotrading/data_trash/y_train.h5').expanduser(), 'table')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1.0    290022\n",
       " 1.0    263049\n",
       "Name: bin, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "neg, pos = y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "290022"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "\n",
    "under = RandomUnderSampler()\n",
    "\n",
    "_, _ = under.fit_sample(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([417835, 485784,  63550, ..., 553068, 553069, 553070], dtype=int64)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "under.sample_indices_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_re = X.iloc[under.sample_indices_].sort_index()\n",
    "y_re = y.iloc[under.sample_indices_].sort_index()\n",
    "events_re = events.iloc[under.sample_indices_].sort_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\doda\\Anaconda3\\envs\\fincl2\\lib\\site-packages\\sklearn\\model_selection\\_search.py:823: FutureWarning: The parameter 'iid' is deprecated in 0.22 and will be removed in 0.24.\n",
      "  \"removed in 0.24.\", FutureWarning\n"
     ]
    }
   ],
   "source": [
    "clf = LGBMClassifier()\n",
    "param_grid = LGBM_PARAM_GRID\n",
    "hypers_n_iter = 5\n",
    "num_threads = 32\n",
    "search = clf_hyper_fit(\n",
    "    feat=X_re,\n",
    "    lbl=y_re,\n",
    "    t1=events_re[\"t1\"],\n",
    "    pipe_clf=clf,\n",
    "    param_grid=param_grid,\n",
    "    rnd_search_iter=hypers_n_iter,\n",
    "    n_jobs=num_threads,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LGBMClassifier(boosting_type='gbdt', class_weight=None,\n",
       "               colsample_bytree=0.8999999999999999, importance_type='split',\n",
       "               learning_rate=0.1, max_depth=3, min_child_samples=20,\n",
       "               min_child_weight=0.001, min_split_gain=0.0, n_estimators=100,\n",
       "               n_jobs=-1, num_leaves=34, objective=None, random_state=None,\n",
       "               reg_alpha=0.0, reg_lambda=0.0, silent=True, subsample=1.0,\n",
       "               subsample_for_bin=200000, subsample_freq=0)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\doda\\Anaconda3\\envs\\fincl2\\lib\\site-packages\\sklearn\\model_selection\\_search.py:823: FutureWarning: The parameter 'iid' is deprecated in 0.22 and will be removed in 0.24.\n",
      "  \"removed in 0.24.\", FutureWarning\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=PurgedKFold(n_splits=3, pct_embargo=0, random_state=None,\n",
       "      t1=2007-04-27 13:20:00.000042   2007-04-30 08:50:00.000042\n",
       "2007-04-27 13:34:00.000043   2007-04-30 09:35:00.000043\n",
       "2007-04-27 13:39:00.000042   2007-04-30 09:11:00.000042\n",
       "2007-04-27 13:41:00.000021   2007-05-03 10:46:00.000021\n",
       "2007-04-27 13:42:00.000043   2007-04-30 09:53:00.000043\n",
       "2007-04-27 13:44:...8...\n",
       "                                        'n_estimators': array([ 25,  50,  75, 100, 125, 150, 175, 200, 225, 250]),\n",
       "                                        'num_leaves': array([  8,  10,  12,  14,  16,  18,  20,  22,  24,  26,  28,  30,  32,\n",
       "        34,  36,  38,  40,  42,  44,  46,  48,  50,  52,  54,  56,  58,\n",
       "        60,  62,  64,  66,  68,  70,  72,  74,  76,  78,  80,  82,  84,\n",
       "        86,  88,  90,  92,  94,  96,  98, 100, 102, 104, 106, 108, 110,\n",
       "       112, 114, 116, 118, 120, 122, 124, 126, 128])},\n",
       "                   pre_dispatch='2*n_jobs', random_state=None, refit=True,\n",
       "                   return_train_score=False, scoring='neg_log_loss', verbose=0)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search.fit(X_re, y_re)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5331152055886863"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_re, search.predict(X_re), average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\doda\\Anaconda3\\envs\\fincl2\\lib\\site-packages\\sklearn\\model_selection\\_search.py:823: FutureWarning: The parameter 'iid' is deprecated in 0.22 and will be removed in 0.24.\n",
      "  \"removed in 0.24.\", FutureWarning\n"
     ]
    }
   ],
   "source": [
    "search2 = clf_hyper_fit(\n",
    "    feat=X,\n",
    "    lbl=y,\n",
    "    t1=events[\"t1\"],\n",
    "    pipe_clf=clf,\n",
    "    param_grid=param_grid,\n",
    "    rnd_search_iter=hypers_n_iter,\n",
    "    n_jobs=num_threads,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4303082696827688"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y, search2.predict(X), average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def undersample(events, X, y):\n",
    "    from imblearn.under_sampling import RandomUnderSampler\n",
    "    under = RandomUnderSampler()\n",
    "\n",
    "    _, _ = under.fit_sample(X, y)\n",
    "    X_re = X.iloc[under.sample_indices_].sort_index()\n",
    "    y_re = y.iloc[under.sample_indices_].sort_index()\n",
    "    events_re = events.iloc[under.sample_indices_].sort_index()\n",
    "    return X_re, y_re, events_re\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
